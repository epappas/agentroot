//! LLM-based chunk metadata generation
//!
//! Generates rich metadata for individual code/text chunks:
//! - Summary: Brief description of what the chunk does
//! - Purpose: Why this code exists
//! - Concepts: Semantic concepts present in the chunk
//! - Labels: Key-value tags for categorization
//! - Related chunks: Links to semantically related chunks

use crate::error::Result;
use crate::index::ast_chunker::SemanticChunk;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Metadata for a single chunk, generated by LLM
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ChunkMetadata {
    /// Brief summary of what this chunk does (1-2 sentences)
    pub summary: String,

    /// Purpose/intent: why this code exists
    pub purpose: String,

    /// Semantic concepts present in this chunk (3-5 concepts)
    pub concepts: Vec<String>,

    /// Key-value labels for categorization
    /// Examples: {"layer": "service", "operation": "create", "entity": "user"}
    pub labels: HashMap<String, String>,

    /// Related chunk hashes (for navigation/exploration)
    pub related_to: Vec<String>,
}

impl ChunkMetadata {
    /// Create empty metadata
    pub fn empty() -> Self {
        Self {
            summary: String::new(),
            purpose: String::new(),
            concepts: Vec::new(),
            labels: HashMap::new(),
            related_to: Vec::new(),
        }
    }
}

/// Context for generating chunk metadata
#[derive(Debug, Clone)]
pub struct ChunkContext {
    /// Document path
    pub document_path: String,

    /// Chunk type (Function, Method, Class, etc.)
    pub chunk_type: String,

    /// Breadcrumb (e.g., "MyClass::my_method")
    pub breadcrumb: Option<String>,

    /// Programming language
    pub language: Option<String>,

    /// Line numbers (for context)
    pub start_line: usize,
    pub end_line: usize,

    /// Surrounding chunks (for context)
    pub previous_chunk: Option<String>,
    pub next_chunk: Option<String>,
}

/// Generate metadata for chunks using LLM
pub async fn generate_chunk_metadata(
    chunk: &SemanticChunk,
    context: &ChunkContext,
    client: &dyn super::LLMClient,
) -> Result<ChunkMetadata> {
    // Build prompt for chunk metadata generation
    let prompt = build_chunk_metadata_prompt(chunk, context);

    // Call LLM
    let messages = vec![
        super::ChatMessage {
            role: "system".to_string(),
            content: CHUNK_METADATA_SYSTEM_PROMPT.to_string(),
        },
        super::ChatMessage {
            role: "user".to_string(),
            content: prompt,
        },
    ];

    let response = client.chat_completion(messages).await?;

    // Parse JSON response
    parse_chunk_metadata_response(&response)
}

const CHUNK_METADATA_SYSTEM_PROMPT: &str = r#"You are an expert code analyst. Your task is to analyze code chunks and generate structured metadata in JSON format.

For each chunk, provide:
1. summary: A brief 1-2 sentence description of what this code does
2. purpose: Why this code exists (the "why", not the "what")
3. concepts: 3-5 semantic concepts or design patterns present (e.g., "dependency injection", "validation", "caching")
4. labels: Key-value pairs for categorization (e.g., {"layer": "service", "operation": "create", "domain": "user"})
5. related_to: Empty array (will be populated later via semantic analysis)

IMPORTANT:
- Be concise and technical
- Focus on semantic meaning, not implementation details
- Use industry-standard terminology for concepts
- Labels should be useful for filtering and organization
- Always return valid JSON

Example output:
{
  "summary": "Validates user email addresses using regex pattern matching",
  "purpose": "Ensure data quality by rejecting invalid email formats before database insertion",
  "concepts": ["input validation", "regex", "data quality", "email validation"],
  "labels": {
    "operation": "validation",
    "entity": "email",
    "layer": "validation"
  },
  "related_to": []
}"#;

fn build_chunk_metadata_prompt(chunk: &SemanticChunk, context: &ChunkContext) -> String {
    let mut prompt = String::new();

    prompt.push_str(&format!(
        "Document: {}\nType: {}\n",
        context.document_path, context.chunk_type
    ));

    if let Some(breadcrumb) = &context.breadcrumb {
        prompt.push_str(&format!("Location: {}\n", breadcrumb));
    }

    if let Some(lang) = &context.language {
        prompt.push_str(&format!("Language: {}\n", lang));
    }

    prompt.push_str(&format!(
        "Lines: {}-{}\n\n",
        context.start_line, context.end_line
    ));

    // Add surrounding context if available
    if let Some(prev) = &context.previous_chunk {
        let preview = prev.chars().take(100).collect::<String>();
        prompt.push_str(&format!("Previous chunk: {}...\n\n", preview));
    }

    prompt.push_str("Code to analyze:\n```\n");
    prompt.push_str(&chunk.text);
    prompt.push_str("\n```\n\n");

    if let Some(next) = &context.next_chunk {
        let preview = next.chars().take(100).collect::<String>();
        prompt.push_str(&format!("\nNext chunk: {}...\n", preview));
    }

    prompt.push_str("\nGenerate metadata for this chunk in JSON format:");

    prompt
}

fn parse_chunk_metadata_response(response: &str) -> Result<ChunkMetadata> {
    // Try to extract JSON from response (LLM might wrap it in markdown)
    let json_str = if let Some(start) = response.find('{') {
        if let Some(end) = response.rfind('}') {
            &response[start..=end]
        } else {
            response
        }
    } else {
        response
    };

    // Parse JSON
    let metadata: ChunkMetadata = serde_json::from_str(json_str)
        .map_err(|e| crate::error::AgentRootError::Llm(format!("Failed to parse chunk metadata JSON: {}", e)))?;

    Ok(metadata)
}

/// Generate metadata for all chunks in a document (batched for efficiency)
pub async fn generate_batch_chunk_metadata(
    chunks: &[SemanticChunk],
    document_path: &str,
    language: Option<&str>,
    client: &dyn super::LLMClient,
) -> Result<Vec<ChunkMetadata>> {
    let mut metadata_list = Vec::new();

    for (i, chunk) in chunks.iter().enumerate() {
        let context = ChunkContext {
            document_path: document_path.to_string(),
            chunk_type: format!("{:?}", chunk.chunk_type),
            breadcrumb: chunk.metadata.breadcrumb.clone(),
            language: language.map(|s| s.to_string()),
            start_line: chunk.metadata.start_line,
            end_line: chunk.metadata.end_line,
            previous_chunk: if i > 0 {
                Some(chunks[i - 1].text.clone())
            } else {
                None
            },
            next_chunk: if i < chunks.len() - 1 {
                Some(chunks[i + 1].text.clone())
            } else {
                None
            },
        };

        let metadata = generate_chunk_metadata(chunk, &context, client).await?;
        metadata_list.push(metadata);
    }

    Ok(metadata_list)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_chunk_metadata_response() {
        let response = r#"{
  "summary": "Validates user email addresses using regex",
  "purpose": "Ensure data quality before database insertion",
  "concepts": ["validation", "regex", "email"],
  "labels": {
    "operation": "validation",
    "entity": "email"
  },
  "related_to": []
}"#;

        let metadata = parse_chunk_metadata_response(response).unwrap();
        assert_eq!(
            metadata.summary,
            "Validates user email addresses using regex"
        );
        assert_eq!(metadata.concepts.len(), 3);
        assert_eq!(metadata.labels.get("operation"), Some(&"validation".to_string()));
    }

    #[test]
    fn test_parse_chunk_metadata_with_markdown() {
        let response = r#"Here's the metadata:
```json
{
  "summary": "Test summary",
  "purpose": "Test purpose",
  "concepts": ["test"],
  "labels": {},
  "related_to": []
}
```"#;

        let metadata = parse_chunk_metadata_response(response).unwrap();
        assert_eq!(metadata.summary, "Test summary");
    }
}
